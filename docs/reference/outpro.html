<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Model and subsapce aware out-of-distribution (OOD) scoring with outPro — outpro • Model-Independent Variable Selection with Variable Priority</title><!-- favicons --><link rel="icon" type="image/png" sizes="48x48" href="../favicon-48x48.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Model and subsapce aware out-of-distribution (OOD) scoring with outPro — outpro"><meta property="og:description" content="

outpro computes an out-of-distribution (OOD) score for new
inputs using a fitted model, integrating variable prioritization and
local neighborhoods derived from the model. The procedure is model aware
and subspace aware: it scores departures in the coordinates that the
model has learned to rely on, rather than relying on a global distance
in the full feature space. Applicable across all outcome types."><meta property="og:image" content="https://www.randomforestsrc.org/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-WZWXVK817Z"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WZWXVK817Z');
</script></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">Model-Independent Variable Selection with Variable Priority</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../articles/getstarted.html">
    <span class="fas fa-home fa-lg"></span>

    Getting Started
  </a>
</li>
<li>
  <a href="../articles/installation.html">Installation</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignettes

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/speedup.html">Speedup VarPro Analyses</a>
    </li>
    <li>
      <a href="../articles/survival.html">Survival Problems</a>
    </li>
    <li>
      <a href="../articles/unsupervise.html">Unsupervised Problems</a>
    </li>
    <li>
      <a href="../articles/ivarpro.html">Individual Variable Priority (iVarPro)</a>
    </li>
    <li>
      <a href="../articles/partialpro.html">Partial Effects</a>
    </li>
    <li>
      <a href="../articles/isopro.html">Identify Anomalous Data</a>
    </li>
  </ul></li>
<li>
  <a href="../reference/index.html">Manual</a>
</li>
<li>
  <a href="https://github.com/kogalur/varPro/issues" class="external-link">Bug Reporting</a>
</li>
<li>
  <a href="https://github.com/kogalur/varPro/discussions" class="external-link">Discussions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="https://github.com/kogalur/varPro/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

    GitHub
  </a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/kogalur/varPro/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

    GitHub
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Model and subsapce aware out-of-distribution (OOD) scoring with outPro</h1>

    <div class="hidden name"><code>outpro.Rd</code></div>
    </div>

    <div class="ref-description">


<p><code>outpro</code> computes an out-of-distribution (OOD) score for new
inputs using a fitted model, integrating variable prioritization and
local neighborhoods derived from the model. The procedure is model aware
and subspace aware: it scores departures in the coordinates that the
model has learned to rely on, rather than relying on a global distance
in the full feature space. Applicable across all outcome types.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">outpro</span><span class="op">(</span><span class="va">object</span>,</span>
<span>       <span class="va">newdata</span>,</span>
<span>       neighbor <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>       distancef <span class="op">=</span> <span class="st">"prod"</span>,</span>
<span>       reduce <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>       cutoff <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>       max.rules.tree <span class="op">=</span> <span class="fl">150</span>,</span>
<span>       max.tree <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">outpro.null</span><span class="op">(</span><span class="va">object</span>,</span>
<span>            nulldata <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>            neighbor <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>            distancef <span class="op">=</span> <span class="st">"prod"</span>,</span>
<span>            reduce <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>            cutoff <span class="op">=</span> <span class="fl">.79</span>,</span>
<span>            max.rules.tree <span class="op">=</span> <span class="fl">150</span>,</span>
<span>            max.tree <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="details">
    <h2>Details</h2>


<p>Out-of-distribution (OOD) detection is essential for determining when a
supervised model encounters inputs that differ in ways that matter for
prediction. The approach here embeds variable prioritization directly in
the detection step, constructing localized, task relevant neighborhoods
from the fitted model and aggregating coordinate wise deviations within
the selected subspace to obtain a distance value for an input.</p>
<p>For a <code>varpro</code> object, variable prioritization is obtained from the
model and controlled by <code>cutoff</code>. For an <code>rfsrc</code> object, all
predictors are used unless a reduction is supplied. Distances are
computed after standardizing the selected variables with training means
and scales. Variables with zero standard deviation in the training data
are removed automatically before scoring.</p>
<p>The multiplicative <code>"prod"</code> metric uses a small \(\epsilon\) to
avoid zero multiplicands. Since differences are measured on a
standardized scale, \(\epsilon\) is set automatically by default as a
small fraction of the median absolute coordinate difference across
variables and neighbors; users can keep the default or pass a custom
value via <code>out.distance</code> if calling it directly.</p>
<p>The Mahalanobis option uses absolute differences by design and the
covariance of standardized training features. A small ridge is added to
the covariance for numerical stability.</p>
    </div>
    <div id="arguments">
    <h2>Arguments</h2>


<p></p>
<dl><dt id="arg-object">object<a class="anchor" aria-label="anchor" href="#arg-object"></a></dt>
<dd><p>A fitted <code>varpro</code> object or an <code>rfsrc</code> object
    with classes <code>c("rfsrc","grow")</code>.</p></dd>


  <dt id="arg-newdata">newdata<a class="anchor" aria-label="anchor" href="#arg-newdata"></a></dt>
<dd><p>New data to score. If omitted, the training design
  matrix is used. For <code>varpro</code> objects, encodings are aligned to
  training with <code>get.hotencode.test</code>.</p></dd>


  <dt id="arg-neighbor">neighbor<a class="anchor" aria-label="anchor" href="#arg-neighbor"></a></dt>
<dd><p>Number of training neighbors per case, as determined
  by the model structure. If <code>NULL</code>, a default of <code>min(n/10,
    5000)</code> is used where <code>n</code> is the number of training rows.</p></dd>


  <dt id="arg-distancef">distancef<a class="anchor" aria-label="anchor" href="#arg-distancef"></a></dt>
<dd><p>Distance function for aggregation. One of
  <code>"prod"</code>, <code>"euclidean"</code>, <code>"mahalanobis"</code>,
  <code>"manhattan"</code>, <code>"minkowski"</code>, <code>"kernel"</code>. The default
  is <code>"prod"</code>.</p></dd>


  <dt id="arg-reduce">reduce<a class="anchor" aria-label="anchor" href="#arg-reduce"></a></dt>
<dd><p>Controls variable selection. If <code>TRUE</code> with a
    <code>varpro</code> object, uses model based prioritization with threshold
    <code>cutoff</code>. A character vector selects variables by name. A named
    numeric vector supplies variable weights. Otherwise all predictors
    are used with unit weights.</p></dd>


  <dt id="arg-cutoff">cutoff<a class="anchor" aria-label="anchor" href="#arg-cutoff"></a></dt>
<dd><p>Threshold used with <code>varpro</code> variable importance
  <code>z</code>. If <code>NULL</code>, a default based on the number of predictors
  is used: <code>.79</code> when the number of predictors is not large, else
  <code>0</code>.</p></dd>


  <dt id="arg-max-rules-tree">max.rules.tree<a class="anchor" aria-label="anchor" href="#arg-max-rules-tree"></a></dt>
<dd><p>Maximum number of rules per tree for neighbor
    extraction.</p></dd>


  <dt id="arg-max-tree">max.tree<a class="anchor" aria-label="anchor" href="#arg-max-tree"></a></dt>
<dd><p>Maximum number of trees to use for neighbor
    extraction.</p></dd>


  <dt id="arg-nulldata">nulldata<a class="anchor" aria-label="anchor" href="#arg-nulldata"></a></dt>
<dd><p>For <code>outpro.null</code>, optional data representing an
  in distribution reference. If omitted, the training design matrix is
  used.</p></dd>


</dl></div>
    <div id="value">
    <h2>Value</h2>


<p><code>outpro</code> returns a list with components:</p>
<ul><li><p><code>distance</code>: numeric vector of length <code>nrow(newdata)</code> with one score per case.</p></li>
<li><p><code>distance.object</code>: ingredients used for distance computation, including</p><ul><li><p><code>score</code>: neighbor frames returned by <code>varpro.strength</code>.</p></li>
<li><p><code>neighbor</code>: neighbor count per case.</p></li>
<li><p><code>xvar.names</code>: selected variable names after zero sd removal.</p></li>
<li><p><code>xvar.wt</code>: variable weights used after normalization.</p></li>
<li><p><code>dist.xvar</code>: list of absolute coordinate difference matrices (neighbors by cases) in standardized units.</p></li>
<li><p><code>xorg.scale</code>, <code>xnew.scale</code>: standardized training and test matrices for the selected variables.</p></li>
<li><p><code>means</code>, <code>sds</code>: training means and scales for the selected variables.</p></li>
<li><p><code>dropped.zero.sd.variables</code>: variables removed due to zero standard deviation in training.</p></li>
</ul></li>
<li><p><code>distance.args</code>: list of metric arguments actually used,
      including <code>distancef</code>, <code>weights.used</code>,
      <code>normalize.weights</code>, <code>p</code>, and <code>epsilon.used</code>.</p></li>
<li><p><code>score</code>: the neighbor information returned by <code>varpro.strength</code>.</p></li>
<li><p><code>neighbor</code>: neighbor setting used.</p></li>
<li><p><code>cutoff</code>: cutoff used for variable prioritization.</p></li>
<li><p><code>oob.bits</code>: indicator of whether scoring was done on training rows or new data.</p></li>
<li><p><code>selected.variables</code>: the variables used in scoring after all filters.</p></li>
<li><p><code>selected.weights</code>: the normalized squared weights for the selected variables.</p></li>
<li><p><code>means</code>, <code>sds</code>: duplicates for convenience.</p></li>
<li><p><code>call</code>: the matched call.</p></li>
</ul><p><code>outpro.null</code> returns the same list with two additional components:</p>
<ul><li><p><code>cdf</code>: the empirical distribution function of <code>distance</code>.</p></li>
<li><p><code>quantile</code>: the empirical cumulative probability for each scored case.</p></li>
</ul></div>
    <div id="background">
    <h2>Background</h2>


<p>The method follows a model centered view of out-of-distribution (OOD)
  detection that is both model aware and subspace aware. Variable
  prioritization is embedded directly in the detection process to focus
  on coordinates that matter for prediction and to discount nuisance
  directions. Scoring does not rely on global feature density
  estimation. The implementation uses a random forest engine whose rule
  based structure provides localized neighborhoods reflecting the
  learned predictive mapping.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="varpro.html">varpro</a></code>, <code><a href="https://www.randomforestsrc.org//reference/rfsrc.html">rfsrc</a></code>.</p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span></span>
<span><span class="co"># \donttest{</span></span>
<span></span>
<span><span class="co">## ------------------------------------------------</span></span>
<span></span>
<span><span class="co">## fit a varPro model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">BostonHousing</span>, package <span class="op">=</span> <span class="st">"mlbench"</span><span class="op">)</span></span>
<span><span class="va">smp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">BostonHousing</span><span class="op">)</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">BostonHousing</span><span class="op">)</span> <span class="op">*</span> <span class="fl">.75</span><span class="op">)</span></span>
<span><span class="va">train.data</span> <span class="op">&lt;-</span> <span class="va">BostonHousing</span><span class="op">[</span><span class="va">smp</span>,<span class="op">]</span></span>
<span><span class="va">test.data</span> <span class="op">&lt;-</span> <span class="va">BostonHousing</span><span class="op">[</span><span class="op">-</span><span class="va">smp</span>,<span class="op">]</span></span>
<span><span class="va">vp</span> <span class="op">&lt;-</span> <span class="fu"><a href="varpro.html">varpro</a></span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train.data</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Score new data with default multiplicative metric</span></span>
<span><span class="va">op</span> <span class="op">&lt;-</span> <span class="fu">outpro</span><span class="op">(</span><span class="va">vp</span>, newdata <span class="op">=</span> <span class="va">test.data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">op</span><span class="op">$</span><span class="va">distance</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Calibrate a null distribution using training data</span></span>
<span><span class="va">op.null</span> <span class="op">&lt;-</span> <span class="fu">outpro.null</span><span class="op">(</span><span class="va">vp</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">op.null</span><span class="op">$</span><span class="va">quantile</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># }</span></span></code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by <a href="https://www.luminwin.net" class="external-link">Min Lu</a>.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

      </footer></div>






  </body></html>

